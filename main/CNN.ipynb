{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN分类\n",
    "导入所需库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义CNN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=17):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 28 * 28, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片格式转化并加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Analgesic': 0, 'Anti-inflammatory': 1, 'Antibacterial': 2, 'Antidepressant': 3, 'Antidiabetic': 4, 'Antifungal': 5, 'Antihistamine': 6, 'Antihypertensive': 7, 'Antioxidant': 8, 'Antiprotozoal': 9, 'Antipyretic': 10, 'Antispasmodic': 11, 'Antitumor': 12, 'Antiviral': 13, 'Diuretic': 14, 'Hypnotic': 15, 'Sedative': 16}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(root='E:\\\\code\\\\Jupyter\\\\final_repo\\\\pics', transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "class_to_idx = dataset.class_to_idx\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimpleCNN(num_classes=17)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = correct / total * 100\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, Val Accuracy: {val_acc:.2f}%')\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_cnn_model2.pth')\n",
    "    print(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "# 评估函数\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型  \n",
    "(之前训练过一轮，有图片证明，模型保存至CNN_Model.pth,不小心重启了一次)  \n",
    "![本地图片](train_info.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 2.9968, Train Accuracy: 13.23%, Val Accuracy: 20.61%\n",
      "Epoch [2/30], Train Loss: 2.4048, Train Accuracy: 21.45%, Val Accuracy: 28.33%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 22\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_26916\\1579089669.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_cnn_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 43.23%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and evaluate on validation set\n",
    "model.load_state_dict(torch.load(r'E:\\code\\Jupyter\\final_repo\\best_cnn_model.pth'))\n",
    "val_acc = evaluate(model, val_loader)\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试计算某药性的所有图片准确率\n",
    "有完整结果，图片为证（重启了懒得等他跑了）  \n",
    "![本地图片](text_info.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_36504\\1670593622.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r'E:\\code\\Jupyter\\final_repo\\CNN_Model.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream"
         },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[0;32m     26\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Predicted Class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mpredicted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,progress: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m lens \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clas \u001b[38;5;241m==\u001b[39m predicted\u001b[38;5;241m.\u001b[39mitem():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "pre_test_folder = r'E:\\code\\Jupyter\\final_repo\\pics'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# 加载模型权重\n",
    "model.load_state_dict(torch.load(r'E:\\code\\Jupyter\\final_repo\\CNN_Model.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "count = 0\n",
    "lens = 0\n",
    "classes = {'Analgesic': 0, 'Anti-inflammatory': 1, 'Antibacterial': 2, 'Antidepressant': 3, 'Antidiabetic': 4, 'Antifungal': 5, 'Antihistamine': 6, 'Antihypertensive': 7, 'Antioxidant': 8, 'Antiprotozoal': 9, 'Antipyretic': 10, 'Antispasmodic': 11, 'Antitumor': 12, 'Antiviral': 13, 'Diuretic': 14, 'Hypnotic': 15, 'Sedative': 16}\n",
    "clas = 0\n",
    "for i in classes:\n",
    "    test_folder = pre_test_folder + '\\\\' + i    \n",
    "    # 遍历文件夹中的所有图片\n",
    "    for filename in os.listdir(test_folder):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            img_path = os.path.join(test_folder, filename)\n",
    "            image = Image.open(img_path).convert('RGB')  # 确保图像是RGB格式\n",
    "            image = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "            # 预测\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "            print(f'Image: {filename}, Predicted Class: {predicted.item()},progress: {lens}')\n",
    "            lens += 1\n",
    "            if clas == predicted.item():\n",
    "                count += 1\n",
    "    print(f'{i} Accuracy: {count/lens}')\n",
    "    clas += 1\n",
    "    lens = 0\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试单一图片的可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_36504\\330104571.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('CNN_Model.pth', map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n",
      "Predicted class name: Analgesic\n",
      "Class: Analgesic, Probability: 0.6186\n",
      "Class: Anti-inflammatory, Probability: 0.1782\n",
      "Class: Antibacterial, Probability: 0.0101\n",
      "Class: Antidepressant, Probability: 0.0186\n",
      "Class: Antidiabetic, Probability: 0.0002\n",
      "Class: Antifungal, Probability: 0.0074\n",
      "Class: Antihistamine, Probability: 0.0145\n",
      "Class: Antihypertensive, Probability: 0.0008\n",
      "Class: Antioxidant, Probability: 0.0926\n",
      "Class: Antiprotozoal, Probability: 0.0027\n",
      "Class: Antipyretic, Probability: 0.0391\n",
      "Class: Antispasmodic, Probability: 0.0021\n",
      "Class: Antitumor, Probability: 0.0007\n",
      "Class: Antiviral, Probability: 0.0055\n",
      "Class: Diuretic, Probability: 0.0019\n",
      "Class: Hypnotic, Probability: 0.0033\n",
      "Class: Sedative, Probability: 0.0037\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "classes = {'Analgesic': 0, 'Anti-inflammatory': 1, 'Antibacterial': 2, 'Antidepressant': 3, 'Antidiabetic': 4, 'Antifungal': 5, 'Antihistamine': 6, 'Antihypertensive': 7, 'Antioxidant': 8, 'Antiprotozoal': 9, 'Antipyretic': 10, 'Antispasmodic': 11, 'Antitumor': 12, 'Antiviral': 13, 'Diuretic': 14, 'Hypnotic': 15, 'Sedative': 16}\n",
    "# 进行预测\n",
    "model.load_state_dict(torch.load('CNN_Model.pth', map_location=device))\n",
    "def predict(image_path):\n",
    "    image = load_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)  # 使用 softmax 获取概率分布\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted.item(), probabilities.cpu().numpy()\n",
    "\n",
    "# 示例：输入图片路径进行预测\n",
    "image_path = r'E:\\code\\Jupyter\\final_repo\\pics\\Analgesic\\CID_904.png'\n",
    "predicted_class, probabilities = predict(image_path)\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "\n",
    "# 获取标签名称\n",
    "class_names = dataset.classes\n",
    "print(f'Predicted class name: {class_names[predicted_class]}')\n",
    "\n",
    "# 打印概率分布\n",
    "for i, prob in enumerate(probabilities[0]):\n",
    "    print(f'Class: {class_names[i]}, Probability: {prob:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_DIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

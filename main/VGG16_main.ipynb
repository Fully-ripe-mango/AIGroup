{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 期末大作业  \n",
    "首先导入头文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChemicalMoleculeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 数据集的根目录，包含各类药物文件夹\n",
    "            transform (callable, optional): 可选的图像转换（如标准化、数据增强等）\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # 预定义药物类别\n",
    "        self.subclasses = ['Analgesic', 'Antibacterial', 'Antidepressant', 'Antidiabetic',\n",
    "                           'Antifungal', 'Antihistamine', 'Antihypertensive', 'Antioxidant',\n",
    "                           'Antiprotozoal', 'Antipyretic', 'Antispasmodic', 'Antitumor',\n",
    "                           'Antiviral', 'Diuretic', 'Hypnotic', 'Sedative', 'Anti-inflammatory']\n",
    "        \n",
    "        # 遍历每个类别文件夹\n",
    "        for label, subdir in enumerate(self.subclasses):\n",
    "            subdir_path = os.path.join(root_dir, subdir)\n",
    "            if os.path.exists(subdir_path):\n",
    "                for filename in os.listdir(subdir_path):\n",
    "                    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                        self.images.append(os.path.join(subdir_path, filename))\n",
    "                        self.labels.append(label)  # 每个子文件夹对应一个标签（从0开始）\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert('RGB')  # 将灰度图像转换为 RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像转化并创建数据集，将其分为8:2数据集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像转换（包括数据增强和标准化）\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整图像大小为224x224，以适应VGG16输入尺寸\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转（数据增强）\n",
    "    transforms.ToTensor(),  # 转换为tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "])\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = ChemicalMoleculeDataset(root_dir=r'E:\\code\\Jupyter\\final_repo\\pics', transform=transform)\n",
    "\n",
    "# 将数据集分成训练集和验证集\n",
    "train_size = int(0.8 * len(train_dataset))  # 80%作为训练集\n",
    "val_size = len(train_dataset) - train_size  # 20%作为验证集\n",
    "train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "我们将使用 VGG16 作为基础模型，并修改最后一层全连接层，以适应二分类任务（炎症治疗有效 vs 无炎症治疗效果）。此外，我们使用预训练的 VGG16 模型，并将除最后一层外的参数固定，以便更快地收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\code\\Jupyter\\Dive-into-DL-PyTorch\\ENV_DIR\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\code\\Jupyter\\Dive-into-DL-PyTorch\\ENV_DIR\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Conv2d):  # 卷积层初始化\n",
    "            init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(module, nn.Linear):  # 全连接层初始化\n",
    "            init.xavier_normal_(module.weight)\n",
    "        elif isinstance(module, nn.BatchNorm2d):  # 批归一化层初始化\n",
    "            init.constant_(module.weight, 1)\n",
    "            init.constant_(module.bias, 0)\n",
    "# 使用随机初始化的VGG16模型\n",
    "\n",
    "model = models.vgg16(pretrained=False)\n",
    "\n",
    "# 冻结前面几层的参数，只训练最后的全连接层\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# \n",
    "model.classifier[6] = nn.Linear(4096, 17)  # 输出2个类别：炎症治疗有效（1）和无炎症治疗效果（0）\n",
    "\n",
    "# 初始化权重\n",
    "initialize_weights(model)\n",
    "\n",
    "# 将模型移到GPU（如果有可用的GPU）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数和优化器\n",
    "我们使用 交叉熵损失 作为损失函数，因为这是二分类问题的标准选择。优化器使用 Adam，并只更新最后一层的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 使用Adam优化器，只更新最后一层的参数\n",
    "optimizer = optim.Adam(model.classifier[6].parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型\n",
    "接下来，我们定义训练函数。每个 epoch 包括训练和验证两个阶段。我们会在每个 epoch 后保存验证集上表现最好的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 2.6494, Train Accuracy: 12.03%, Val Accuracy: 7.93%\n",
      "Epoch [2/30], Train Loss: 2.6465, Train Accuracy: 12.47%, Val Accuracy: 17.60%\n",
      "Epoch [3/30], Train Loss: 2.6513, Train Accuracy: 12.28%, Val Accuracy: 10.89%\n",
      "Epoch [4/30], Train Loss: 2.6399, Train Accuracy: 12.60%, Val Accuracy: 16.33%\n",
      "Epoch [5/30], Train Loss: 2.6616, Train Accuracy: 11.90%, Val Accuracy: 12.42%\n",
      "Epoch [6/30], Train Loss: 2.6577, Train Accuracy: 11.65%, Val Accuracy: 16.49%\n",
      "Epoch [7/30], Train Loss: 2.6597, Train Accuracy: 12.50%, Val Accuracy: 11.15%\n",
      "Epoch [8/30], Train Loss: 2.6520, Train Accuracy: 12.24%, Val Accuracy: 17.65%\n",
      "Epoch [9/30], Train Loss: 2.6616, Train Accuracy: 12.37%, Val Accuracy: 18.29%\n",
      "Epoch [10/30], Train Loss: 2.6556, Train Accuracy: 12.13%, Val Accuracy: 11.52%\n",
      "Epoch [11/30], Train Loss: 2.6574, Train Accuracy: 11.76%, Val Accuracy: 13.16%\n",
      "Epoch [12/30], Train Loss: 2.6526, Train Accuracy: 12.60%, Val Accuracy: 15.64%\n",
      "Epoch [13/30], Train Loss: 2.6539, Train Accuracy: 12.50%, Val Accuracy: 21.62%\n",
      "Epoch [14/30], Train Loss: 2.6543, Train Accuracy: 12.81%, Val Accuracy: 18.87%\n",
      "Epoch [15/30], Train Loss: 2.6516, Train Accuracy: 13.35%, Val Accuracy: 19.34%\n",
      "Epoch [16/30], Train Loss: 2.6517, Train Accuracy: 12.53%, Val Accuracy: 21.35%\n",
      "Epoch [17/30], Train Loss: 2.6505, Train Accuracy: 13.14%, Val Accuracy: 10.99%\n",
      "Epoch [18/30], Train Loss: 2.6665, Train Accuracy: 12.10%, Val Accuracy: 17.76%\n",
      "Epoch [19/30], Train Loss: 2.6669, Train Accuracy: 13.34%, Val Accuracy: 14.90%\n",
      "Epoch [20/30], Train Loss: 2.6572, Train Accuracy: 12.32%, Val Accuracy: 18.87%\n",
      "Epoch [21/30], Train Loss: 2.6578, Train Accuracy: 12.66%, Val Accuracy: 3.28%\n",
      "Epoch [22/30], Train Loss: 2.6638, Train Accuracy: 12.48%, Val Accuracy: 0.42%\n",
      "Epoch [23/30], Train Loss: 2.6686, Train Accuracy: 12.99%, Val Accuracy: 15.06%\n",
      "Epoch [24/30], Train Loss: 2.6540, Train Accuracy: 13.21%, Val Accuracy: 17.97%\n",
      "Epoch [25/30], Train Loss: 2.6546, Train Accuracy: 12.62%, Val Accuracy: 21.46%\n",
      "Epoch [26/30], Train Loss: 2.6680, Train Accuracy: 12.78%, Val Accuracy: 8.46%\n",
      "Epoch [27/30], Train Loss: 2.6652, Train Accuracy: 13.19%, Val Accuracy: 20.03%\n",
      "Epoch [28/30], Train Loss: 2.6748, Train Accuracy: 12.66%, Val Accuracy: 9.30%\n",
      "Epoch [29/30], Train Loss: 2.6587, Train Accuracy: 12.76%, Val Accuracy: 11.95%\n",
      "Epoch [30/30], Train Loss: 2.6678, Train Accuracy: 13.01%, Val Accuracy: 20.30%\n",
      "Training completed. Best validation accuracy: 21.62%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_acc = 0.0  # 保存验证集上的最佳准确率\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 设置为训练模式\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 更新参数\n",
    "            \n",
    "            # 计算训练集精度\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_acc = correct / total * 100\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, Val Accuracy: {val_acc:.2f}%')\n",
    "        \n",
    "        # 保存最好的模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    print(f\"Training completed. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "# 验证函数\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()  # 设置为评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 不需要计算梯度\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total * 100\n",
    "\n",
    "# 开始训练\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估和测试模型\n",
    "训练完成后，我们可以加载最佳模型，并在验证集或测试集上评估其性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_13348\\3476412898.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 21.04%\n"
     ]
    }
   ],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# 在验证集上测试模型\n",
    "val_acc = evaluate(model, val_loader)\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV_DIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
